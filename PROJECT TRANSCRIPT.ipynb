{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "260679bb",
   "metadata": {},
   "source": [
    "# PROJECT TRANSCRIPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab38177",
   "metadata": {},
   "source": [
    "# 1. Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49506647",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3fabe9",
   "metadata": {},
   "source": [
    "# 2. Import the csv/excel file\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "375f4cae",
   "metadata": {},
   "source": [
    "df = pd.read_csv(r'file_path\\filename.csv')\n",
    "df = pd.read_excel(r'file_path\\filename.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f1050b",
   "metadata": {},
   "source": [
    "# 3. Data Cleaning\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae38fc6e",
   "metadata": {},
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb83b610",
   "metadata": {},
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cbeeb55e",
   "metadata": {},
   "source": [
    "#moving target column to the last position, eg -\n",
    "\n",
    "titles = list(df.columns)\n",
    "titles[13], titles[17] = titles[17], titles[13]\n",
    "titles"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c6e1998",
   "metadata": {},
   "source": [
    "#print data of the required datatype\n",
    "\n",
    "list = list(df.select_dtypes(include=['dtype']).columns)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4fb60584",
   "metadata": {},
   "source": [
    "#to view value count of each column\n",
    "\n",
    "for column in df.columns:\n",
    "     print(\"\\n\" + column)\n",
    "     print(df[column].value_counts())\n",
    "\n",
    "-----------------------------------------\n",
    "\n",
    "#one column\n",
    "df['colname'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843fef90",
   "metadata": {},
   "source": [
    "3.1 Replace blank spaces"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78ec4ea2",
   "metadata": {},
   "source": [
    "#Using DataFrame.mask() method\n",
    "\n",
    "df = df.mask(df == '')\n",
    "\n",
    "------------------------------------------\n",
    "\n",
    "# Replace on all selected columns\n",
    "df2 = df[['col1','col2']].apply(lambda x: x.str.strip()).replace('', np.nan)\n",
    "print(df2)\n",
    "\n",
    "------------------------------------------\n",
    "\n",
    "df['Date'].str.replace(\"-\",\"\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7f567",
   "metadata": {},
   "source": [
    "3.2 Fill nan values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cfc7ca7f",
   "metadata": {},
   "source": [
    "Note : fill numeric with mean and categical with mode (kahi to dekha tha)\n",
    "\n",
    "for col in df.columns:\n",
    "    if col not in ['colname/condition']:\n",
    "        df[col] = df[col].replace(np.nan, df[col].median())\n",
    "-----------------------------\n",
    "\n",
    "#Check nan values\n",
    "df.isnull().sum()\n",
    "df.isnull().sum()/len(df)*100          - #to view percentage of missing data\n",
    "\n",
    "--------------------------------------------\n",
    "# one column\n",
    "df['']  = df[''].fillna(df[''].mode()[0]) \n",
    "\n",
    "--------------------------------------------\n",
    "# all columns\n",
    "df = df.fillna(df.mode())\n",
    "\n",
    "--------------------------------------------\n",
    "#filling all categorical NAN values with mode\n",
    "cols = df.columns\n",
    "df[cols] = df[cols].fillna(df.mode().iloc[0])\n",
    "\n",
    "--------------------------------------------\n",
    "#if target column has missing values, use -\n",
    "1) Mean/Median for Regression\n",
    "2) Mode for Classification- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e8574",
   "metadata": {},
   "source": [
    "3.3 Convert dataype to numeric"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e7a4130",
   "metadata": {},
   "source": [
    "df['col'] = pd.to_numeric(df['col'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c721b1b4",
   "metadata": {},
   "source": [
    "3.4 Label Encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36b2832a",
   "metadata": {},
   "source": [
    "#object/str -> float\n",
    "df[''] = le.fit_transform((df['']).astype(float))\n",
    "\n",
    "--------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df = df.apply(le.fit_transform)\n",
    "df\n",
    "\n",
    "--------------------------------------------\n",
    "\n",
    "#TypeError: Encoders require their input to be uniformly strings or numbers. Got ['float64', 'str']\n",
    "df1 = df1.apply(lambda col: le.fit_transform(col.astype(str)), axis=0, result_type='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa642354",
   "metadata": {},
   "source": [
    "# 3. EDA \n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab1994f3",
   "metadata": {},
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fb8c28",
   "metadata": {},
   "source": [
    "1. Category plots : used to  show category graphs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9de75e1b",
   "metadata": {},
   "source": [
    "1. stripplot : its like categorical scatterplot -\n",
    "sns.stripplot(data = df, x = 'colname', y = 'target') \n",
    "\n",
    "2. countplot : used for data count -\n",
    "sns.countplot(df['colname'])  \n",
    "\n",
    "3. swarmplot : combination of stripplot and violinplot (very time consuming)\n",
    "sns.swarmplot(data = df, x = 'colname', y = 'target') \n",
    "\n",
    "4. catplot : \n",
    "sns.catplot(data = df, x = 'colname', y = 'target', kind = 'plot_name') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331197e",
   "metadata": {},
   "source": [
    "2. Distribution plots : used to show the distribuiton of data / shows density of the data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "089a357a",
   "metadata": {},
   "source": [
    "1. sns.histplot(data = df, x = 'colname', y = 'target')\n",
    "\n",
    "2. sns.distplot(df['colname'])\n",
    "2. sns.distplot(data = df, x = 'colname', kind = 'edcf', col = 'time', hue = 'colname')  \n",
    "\n",
    "3. sns.kdeplot(df['colname'])  \n",
    "\n",
    "4. sns.violinplot(data = df, x = 'colname', y = 'target') \n",
    "\n",
    "5. sns.jointplot(data = df, x = 'colname', y = 'target')\n",
    "\n",
    "6. sns.rugplot(data = df, x = 'colname', y = 'target')\n",
    "\n",
    "7. sns.pairplot(df)\n",
    "- it shows joint & marginal distributions of all pairwise relationships and for each variable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da8cccf",
   "metadata": {},
   "source": [
    "3. Numrical plots - where both axes have numerical value"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da3ccae0",
   "metadata": {},
   "source": [
    "1. sns.scatterplot(data = df, x = 'colname', y = 'target')\n",
    "1. sns.scatterplot(data=df, x='colname', y='target', hue='colname', s=200)\n",
    "   plt.legend(loc = 'lower left', fontsize='10')\n",
    "\n",
    "where, \n",
    "#s is the size of the dots\n",
    "#plt.legend for the legend details () like loc for its position and fontsize\n",
    "\n",
    "2. sns.lineplot(data = df, x = 'colname', y = 'target')\n",
    "\n",
    "3. sns.regplot(data = df, x = 'colname', y = 'target')\n",
    "\n",
    "4. sns.relplot(data = df, x = 'colname', y = 'target')\n",
    "\n",
    "5. sns.boxplot(data = df,  x = 'colname', y = 'target') / sns.distplot(df['colname'])\n",
    "\n",
    "6. sns.lmplot(data = df,  x = 'colname', y = 'target')\n",
    "\n",
    "7. sns.jointplot(data = df, x = 'colname', y = 'target')\n",
    "\n",
    "8. sns.barplot(data = df, x = 'colname', y = 'target')\n",
    "#avoid barplot if you have many categories, your barplot should'nt have more than 10 bars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52dddd8",
   "metadata": {},
   "source": [
    "# 4. Correlation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed657ad3",
   "metadata": {},
   "source": [
    "df.corr().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc61e866",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(15,9))\n",
    "sns.heatmap(df.corr(), annot = True, linewidth = 0.5, linecolor = 'black', cmap = 'RdYlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd36c68",
   "metadata": {},
   "source": [
    "# 4.1 Feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a951aab",
   "metadata": {},
   "source": [
    "1. VIF - variance Inflation Factor"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01336ce1",
   "metadata": {},
   "source": [
    "from scipy import stats\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee976e8c",
   "metadata": {},
   "source": [
    "x = df.drop([\"target\"], axis =1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "68965522",
   "metadata": {},
   "source": [
    "def vif_calc():\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"VIF factor\"] = [variance_inflation_factor(x.values,i) for i in range(x.shape[1])]\n",
    "    vif[\"features\"] = x.columns\n",
    "    print(vif)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c9feaf6",
   "metadata": {},
   "source": [
    "vif_calc()\n",
    "\n",
    "it will show the scores of the columns contributing to the target column, the one with less score/contribution will be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2921bd9",
   "metadata": {},
   "source": [
    "2. Chi2 feature selection/importance"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb1f4aec",
   "metadata": {},
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "best = SelectKBest(score_func = chi2)\n",
    "fit = best.fit(X,Y) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd083219",
   "metadata": {},
   "source": [
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcols = pd.DataFrame(X.columns)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "204588d3",
   "metadata": {},
   "source": [
    "bestcols.nlargest(10,'Score')\n",
    "\n",
    "#It will show the top 10 most imp columns with highest score\n",
    "#We can drop rest of the features except below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490a756e",
   "metadata": {},
   "source": [
    "3. ExtraTreeClassifier method"
   ]
  },
  {
   "cell_type": "raw",
   "id": "446f75ae",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfb8be53",
   "metadata": {},
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "460bf431",
   "metadata": {},
   "source": [
    "impfeat = pd.Series(model.feature_importances_, index = X.columns)\n",
    "impfeat.nlargest(8).plot(kind='barh')\n",
    "plt.show()\n",
    "\n",
    "#it will show top 8 most imp features, you can drop the rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5175c0f9",
   "metadata": {},
   "source": [
    "4. Varience Threshold (Best)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f756eea1",
   "metadata": {},
   "source": [
    "x = df.drop(['target'], axis = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "609ea5b1",
   "metadata": {},
   "source": [
    "def correlation(dataset, threshold):              #creating fucntion with 2 values\n",
    "    corr_columns = set()                          #set of all the names of correlated columns\n",
    "    corr = dataset.corr()                         #correlation function\n",
    "    for i in range (len(corr.columns)):           #i and j are the columns from x and y axes \n",
    "        for j in range(i):\n",
    "            if abs(corr.iloc[i,j]) > threshold:   #absolute coefficient values\n",
    "                columns = corr.columns[i]         #getting the name of the columns\n",
    "                corr_columns.add(columns)\n",
    "    return corr_columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d26cd6fe",
   "metadata": {},
   "source": [
    "corr_feat = correlation(x, 0.8)\n",
    "corr_feat\n",
    "\n",
    "#it will show features which are correlated 80%, we can drop them"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92279a2e",
   "metadata": {},
   "source": [
    "df1 = df.drop(corr_feat, axis =1, inplace = True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37bfa42",
   "metadata": {},
   "source": [
    "# 5. Outlier checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind = 'box', subplots = True, layout = (2,5), figsize = (20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c38872",
   "metadata": {},
   "source": [
    "5.1 Removing outliers using zscore"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff038274",
   "metadata": {},
   "source": [
    "from scipy.stats import zscore\n",
    "z = np.abs(zscore(df))\n",
    "df1 = df[(z<3).all(axis=1)]\n",
    "df.shape, df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df264ca2",
   "metadata": {},
   "source": [
    "5.1.1 When zscore removing all the rows from the dataset when any column has only 1 value"
   ]
  },
  {
   "cell_type": "raw",
   "id": "790bfeda",
   "metadata": {},
   "source": [
    "If your dataframe columns has non-unique value (For example the column full of categorial value of 1). \n",
    "If it's true then zscore turns this column into Nan values. Then np.abs just turns it to True.\n",
    "The reason is you have to fillna before \"np.abs()\"\n",
    "\n",
    "from scipy.stats import zscore\n",
    "z = pd.DataFrame(zscore(df))\n",
    "z.fillna(0, inplace=True)\n",
    "z = np.abs(z<3).all(axis=1)\n",
    "df1 = df[z]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dac6b3d",
   "metadata": {},
   "source": [
    "5.2  Percentage of data loss\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dec2a33b",
   "metadata": {},
   "source": [
    "#percentage of data loss\n",
    "\n",
    "loss = ((old_shape_rows - new_shape_rows) / old_shape_rows)*100\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fbce0d",
   "metadata": {},
   "source": [
    "# 6. Skewness"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d76d16e",
   "metadata": {},
   "source": [
    "df.skew()\n",
    "\n",
    "#data between (-0.5) and (0.5) is normalized"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ee00d3a",
   "metadata": {},
   "source": [
    "#to view the skewness for all the columns at once - (best)\n",
    "\n",
    "plt.figure(figsize=(18,7))\n",
    "for i, column in enumerate(df.columns, 1):\n",
    "    plt.subplot(2,5,i)\n",
    "    sns.distplot(df[column])\n",
    "    \n",
    "-------------------------------------------------\n",
    "\n",
    "fig, ax = plt.subplots(ncols=5, nrows=5, figsize=(20,20))\n",
    "index = 0\n",
    "ax = ax.flatten()\n",
    "\n",
    "for col, value in df.items():\n",
    "    if col!= 'type':\n",
    "        sns.histplot(data=df, x=col, ax=ax[index], kde =  True)\n",
    "        index += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d012e4b5",
   "metadata": {},
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0dec4b49",
   "metadata": {},
   "source": [
    "#Split data into X and Y\n",
    "\n",
    "X = df.drop(['target'], axis = 1)\n",
    "Y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6810294",
   "metadata": {},
   "source": [
    "If data has minimum value 0 or negative values use yeo-johnson else BoxCox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a11349d",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import power_transform\n",
    "X = power_transform(X, method = 'yeo-johnson')\n",
    "X\n",
    "\n",
    "------------------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import power_transform\n",
    "X = power_transform(X, method = 'boxcox')\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6217c9",
   "metadata": {},
   "source": [
    "# 7. Data Scaling"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37432c2b",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X\n",
    "\n",
    "----------------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mn = MinMaxScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "raw",
   "id": "144ef988",
   "metadata": {},
   "source": [
    "#must covert scaled data from numpy array to a dataframe\n",
    "\n",
    "X = pd.DataFrame(X) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e899233",
   "metadata": {},
   "source": [
    "# 7.1 Balance dataset (only for  classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b0b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3eb3348a",
   "metadata": {},
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "X, Y = ros.fit_resample(X,Y)\n",
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2079d275",
   "metadata": {},
   "source": [
    "# 8. Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be47ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb289866",
   "metadata": {},
   "source": [
    "# 9. Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476dc186",
   "metadata": {},
   "source": [
    "Importing metrics"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03ee024f",
   "metadata": {},
   "source": [
    "#classification\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "------------------------------------------------\n",
    "\n",
    "#regression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed19fb",
   "metadata": {},
   "source": [
    "1. Logistic Regression"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15e160b9",
   "metadata": {},
   "source": [
    "#Logistic Regression (C)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred))\n",
    "print(classification_report(Y_test, pred))\n",
    "print(accuracy_score(Y_test, pred))\n",
    "cvs = cross_val_score(lr, X_train, Y_train, cv=None)\n",
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599f4845",
   "metadata": {},
   "source": [
    "2. Linear Regression"
   ]
  },
  {
   "cell_type": "raw",
   "id": "732aac53",
   "metadata": {},
   "source": [
    "#Linear Regression (R)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr=LinearRegression()\n",
    "lr.fit(X_train,Y_train)\n",
    "pred=lr.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(Y_test, pred))\n",
    "print('MSE:', metrics.mean_squared_error(Y_test, pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(Y_test, pred)))\n",
    "print('r2score:', r2_score(Y_test, pred))\n",
    "cvs = cross_val_score(dt, X_train, Y_train, cv=None)\n",
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e87202",
   "metadata": {},
   "source": [
    "3. Decision Tree"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c908dbdb",
   "metadata": {},
   "source": [
    "#Descison Tree Classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,Y_train)\n",
    "pred = dt.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred))\n",
    "print(classification_report(Y_test, pred))\n",
    "print(accuracy_score(Y_test, pred))\n",
    "cvs = cross_val_score(dt, X_train, Y_train, cv=None)\n",
    "cvs.mean()\n",
    "\n",
    "---------------------------------------\n",
    "\n",
    "#Descison Tree Regressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train,Y_train)\n",
    "pred = dt.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(Y_test, pred))\n",
    "print('MSE:', metrics.mean_squared_error(Y_test, pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(Y_test, pred)))\n",
    "print('r2score:', r2_score(Y_test, pred))\n",
    "cvs = cross_val_score(dt, X_train, Y_train, cv=None)\n",
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d5fb85",
   "metadata": {},
   "source": [
    "4. Random Forest"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51e43657",
   "metadata": {},
   "source": [
    "#Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,Y_train)\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred))\n",
    "print(classification_report(Y_test, pred))\n",
    "print(accuracy_score(Y_test, pred))\n",
    "cvs = cross_val_score(rf, X_train, Y_train, cv=None)\n",
    "cvs.mean()\n",
    "\n",
    "---------------------------------------\n",
    "\n",
    "#Random Forest Regressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train,Y_train)\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred))\n",
    "print(classification_report(Y_test, pred))\n",
    "print(accuracy_score(Y_test, pred))\n",
    "cvs = cross_val_score(rf, X_train, Y_train, cv=None)\n",
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1166802",
   "metadata": {},
   "source": [
    "5.  Support Vector Machine"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2b8d00e",
   "metadata": {},
   "source": [
    "#Support Vector Classifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train,Y_train)\n",
    "pred = svc.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred))\n",
    "print(classification_report(Y_test, pred))\n",
    "print(accuracy_score(Y_test, pred))\n",
    "cvs = cross_val_score(svc, X_train, Y_train, cv=None)\n",
    "cvs.mean()\n",
    "\n",
    "---------------------------------------\n",
    "\n",
    "#Support Vector Regressor\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "svr = SVR()\n",
    "svr.fit(X_train,Y_train)\n",
    "pred = svr.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(Y_test, pred))\n",
    "print('MSE:', metrics.mean_squared_error(Y_test, pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(Y_test, pred)))\n",
    "print('r2score:', r2_score(Y_test, pred))\n",
    "cvs = cross_val_score(svr, X_train, Y_train, cv=None)\n",
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0947d322",
   "metadata": {},
   "source": [
    "6. K-Nearest Neighbors "
   ]
  },
  {
   "cell_type": "raw",
   "id": "465489a1",
   "metadata": {},
   "source": [
    "# KNN Classifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred))\n",
    "print(classification_report(Y_test, pred))\n",
    "print(accuracy_score(Y_test, pred))\n",
    "cvs = cross_val_score(knn, X_train, Y_train, cv=None)\n",
    "cvs.mean()\n",
    "\n",
    "--------------------------------------\n",
    "\n",
    "# KNN Regressor\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=4)\n",
    "knn.fit(X_train,Y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(Y_test, pred))\n",
    "print('MSE:', metrics.mean_squared_error(Y_test, pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(Y_test, pred)))\n",
    "print('r2score:', r2_score(Y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfe0220",
   "metadata": {},
   "source": [
    "7. Gradient Boosting"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91928718",
   "metadata": {},
   "source": [
    "#GBClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train,Y_train)\n",
    "pred = gb.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred))\n",
    "print(classification_report(Y_test, pred))\n",
    "print(accuracy_score(Y_test, pred))\n",
    "cvs = cross_val_score(gb, X_train, Y_train, cv=None)\n",
    "cvs.mean()\n",
    "\n",
    "-------------------------------------------------------\n",
    "\n",
    "#GBRegressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train,Y_train)\n",
    "pred = gbr.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(Y_test, pred))\n",
    "print('MSE:', metrics.mean_squared_error(Y_test, pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(Y_test, pred)))\n",
    "print('r2score:', r2_score(Y_test, pred))\n",
    "cvs = cross_val_score(gb, X_train, Y_train, cv=None)\n",
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b52cb5",
   "metadata": {},
   "source": [
    "8. XGBoost"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d543530",
   "metadata": {},
   "source": [
    "#XGBClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train,Y_train)\n",
    "pred = xgb.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred))\n",
    "print(classification_report(Y_test, pred))\n",
    "print(accuracy_score(Y_test, pred))\n",
    "cvs = cross_val_score(xgb, X, Y, cv=None)\n",
    "cvs.mean()\n",
    "\n",
    "------------------------------------------------\n",
    "\n",
    "#XGBRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(X_train,Y_train)\n",
    "pred = xgb.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(Y_test, pred))\n",
    "print('MSE:', metrics.mean_squared_error(Y_test, pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(Y_test, pred)))\n",
    "print('r2score:', r2_score(Y_test, pred))\n",
    "cvs = cross_val_score(xgb, X_train, Y_train, cv=None)\n",
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc6925b",
   "metadata": {},
   "source": [
    "9. AdaBoost"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8cc7aaa",
   "metadata": {},
   "source": [
    "#AdaBoost classifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb = AdaBoostClassifier()\n",
    "adb.fit(X_train,Y_train)\n",
    "pred = adb.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred))\n",
    "print(classification_report(Y_test, pred))\n",
    "print(accuracy_score(Y_test, pred))\n",
    "cvs = cross_val_score(adb, X, Y, cv=None)\n",
    "cvs.mean()\n",
    "\n",
    "---------------------------------------------------\n",
    "\n",
    "#AdaBoost regressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train,Y_train)\n",
    "pred = gbr.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(Y_test, pred))\n",
    "print('MSE:', metrics.mean_squared_error(Y_test, pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(Y_test, pred)))\n",
    "print('r2score:', r2_score(Y_test, pred))\n",
    "cvs = cross_val_score(gb, X_train, Y_train, cv=None)\n",
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a6ce6",
   "metadata": {},
   "source": [
    "9. Naive Bayes "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c59f98c8",
   "metadata": {},
   "source": [
    "#GaussianNB Classifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train,Y_train)\n",
    "pred = nb.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred))\n",
    "print(classification_report(Y_test, pred))\n",
    "print(accuracy_score(Y_test, pred))\n",
    "cvs = cross_val_score(nb, X_train, Y_train, cv=None)\n",
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05452bc0",
   "metadata": {},
   "source": [
    "# 10. Hyperparameter Tuning + Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaf1cf5",
   "metadata": {},
   "source": [
    "1. Randomized / Grid Search CV"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be982406",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db35b699",
   "metadata": {},
   "source": [
    "parameters = [values]   -- #multiple parameters, do not use commas \n",
    "..\n",
    "\n",
    "random_grid = 'paramters' : paramters,\n",
    "..\n",
    "\n",
    "random_grid"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6bc8b7d5",
   "metadata": {},
   "source": [
    "model = model_name\n",
    "rscv = RandomizedSearchCV(estimator = model,\n",
    "                          param_distributions = random_grid, \n",
    "                          n_iter = 100,\n",
    "                          cv = 3,\n",
    "                          n_jobs=-1)\n",
    "                          \n",
    "rscv.fit(X_train,Y_train)\n",
    "rscv\n",
    "\n",
    "--------------------------------------\n",
    "gridcv_grid = {'parameter' : [rscv.best_params_['parameter'],\n",
    "and n_iter is replaced by - verbose = 3"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c25d757f",
   "metadata": {},
   "source": [
    "rscv.fit(X_train,Y_train)\n",
    "rscv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb6318f7",
   "metadata": {},
   "source": [
    "rscv.best_estimator_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edf18a08",
   "metadata": {},
   "source": [
    "best_rscv = rscv.best_estimator_\n",
    "pred = best_rscv.predict(X_test)\n",
    "\n",
    "#classification -\n",
    "print(confusion_matrix(Y_test, pred))\n",
    "print(classification_report(Y_test, pred))\n",
    "print(accuracy_score(Y_test, pred))\n",
    "cvs = cross_val_score(rscv, X_train, Y_train, cv=4)\n",
    "cvs.mean()\n",
    "\n",
    "-----------------------------------------------\n",
    "\n",
    "#regression\n",
    "print('MAE:', metrics.mean_absolute_error(Y_test, pred))\n",
    "print('MSE:', metrics.mean_squared_error(Y_test, pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(Y_test, pred)))\n",
    "print('r2score:', r2_score(Y_test, pred))\n",
    "cvs = cross_val_score(rscv, X_train, Y_train, cv=4)\n",
    "cvs.mean()\n",
    "\n",
    "#In GridSearchCV we don't have an option of iteration, so how do we know it how many iterations will happen?\n",
    "Check the output of the above columns and count the outputs of each parmater and multiply them. \n",
    "eg.-> 4 x 1 x 1 x 4 x 4 x 1 = 16 (Abalone columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbf5a4f",
   "metadata": {},
   "source": [
    "2. Ridge/Lasso (for Linear Refression only)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7df6fabe",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "raw",
   "id": "163b498f",
   "metadata": {},
   "source": [
    "ridge = Ridge()/Lasso()\n",
    "param_grid = {'alpha':[0.001, 0.1, 1,3,6,9,11,16,26,55,80,93,]} #it has only 1 parameter \"alpha\"\n",
    "\n",
    "ridgecv/lassocv = GridSearchCV(ridge, param_grid, scoring ='neg_mean_squared_error', cv=5)\n",
    "ridgecv.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2ab898c",
   "metadata": {},
   "source": [
    "ridgecv.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "23ac7435",
   "metadata": {},
   "source": [
    "ridgecv.best_score_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7194270",
   "metadata": {},
   "source": [
    "ridgecv.predict(X_test)\n",
    "pred = ridgecv.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(Y_test, pred))\n",
    "print('MSE:', metrics.mean_squared_error(Y_test, pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(Y_test, pred)))\n",
    "print('r2score:', r2_score(Y_test, pred))\n",
    "cvs = cross_val_score(ridge, X, Y, cv=None)\n",
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53752a3b",
   "metadata": {},
   "source": [
    "# 11. Cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa61fb85",
   "metadata": {},
   "source": [
    "1. K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89b80b78",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cvs = cross_val_score(model, X, Y, cv=10)\n",
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d5daaa",
   "metadata": {},
   "source": [
    "2. Stratified K-Fold (for imbalanced dataset)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "86f03d1f",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits = 10)\n",
    "skf.split(X,Y)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2c76de6",
   "metadata": {},
   "source": [
    "accuracy= []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state = None)\n",
    "skf.get_n_splits(X,Y)\n",
    "\n",
    "#X is the feature set and Y is the target\n",
    "#Putiing train_index and test_index of X and Y\n",
    "\n",
    "for train_index, test_index in skf.split(X,Y):\n",
    "    print('Train:', train_index, 'Validation:', test_index)\n",
    "    X1_train, X1_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y1_train, Y1_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "    \n",
    "rscv.fit(X1_train, Y1_train)\n",
    "pred = rscv.predict(X1_test)\n",
    "score = accuracy_score(pred, Y1_test)\n",
    "accuracy.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639fe2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(accuracy).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db29b66",
   "metadata": {},
   "source": [
    "3. LeaveOneOut"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e1cd166",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "cvs = LeaveOneOut()\n",
    "cvs(model, X, Y, cv = cv)\n",
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c7420b",
   "metadata": {},
   "source": [
    "# 12. Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2152a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'Project_Name.pkl'\n",
    "pickle.dump(model_name, open(filename, 'wb'))\n",
    "\n",
    "# wb stands for write binary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
